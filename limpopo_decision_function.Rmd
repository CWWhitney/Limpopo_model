---
title: "Generating and calculating causal models for Limpopo"
author: "Eike Luedeling, Cory Whitney"
output: word_document
bibliography:
 - packages.bib
 - references.bib 
---

This document outlines a collection of holistic modeling techniques aimed at describing the link between river flows and livelihoods. We build our models using environmental flows (eflows) of water provided within a river or wetland to maintain aquatic ecosystems. These can also be thought of as ‘ecological water demand’ effectively a balance between water resources development and the need to protect freshwater-dependent ecosystems. The overall objective of the model we outline here is to simulate how river flow, in particular e-flow, impacts smallholder agriculture.  The objective is to make the linkage between sustainable eflows in the rivers, and the water-requirements of sustainable agriculture. The simulation offers insights into the role that river flows play in the ability of agriculture to be sustainable, and the consequent risks to agriculture when river flows are either optimal or when they become marginal. The simulations show a strong positive link between eflows and livelihoods and provide justification for understanding eflows as more than just a mechanism for positive biodiversity outcomes.

We generate a holistic model to simulate the contribution of eflows to sustainable agriculture, food security and livelihoods. Spatially, we do this for only a small portion of the basin as a test-case. We apply holistic modeling approaches to generate conceptual impact pathways and quantitative models to forecast decision outcomes [see @do_decision_2020; @lanzanova_improving_2019; @whitney_probabilistic_2018]. This includes collaborative model development [@whitney_decision_2018-1] to assess farming futures given eflow forecasts under different management options. To build these simulations we use functions from the `decisionSupport` [@R-decisionSupport], `dplyr` [@R-dplyr], `nasapower` [@R-nasapower], `patchwork` [@R-patchwork], `tidyverse` [@R-tidyverse] and `Evapotranspiration` [@R-Evapotranspiration] libraries in the R programming language [@R-base].

```{r, include = F}
#set global options for knitr chunks 
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  dpi=300,
  fig.width=5, 
  fig.height=3.5
)

# Load the necessary libraries 
# devtools::install_github("eikeluedeling/decisionSupport")
library(decisionSupport)
library(dplyr)
library(nasapower)
library(patchwork)
library(tidyverse)
library(Evapotranspiration)

```

```{r, warning = F, include = F}

# Automatically write R package citation entries to a .bib file
knitr::write_bib(c(.packages(),
                   'dplyr',
                   'patchwork',
                   'plyr',
                   'tidyverse',
                   'ggplot2', 
                   'decisionSupport',
                   'nasapower',
                   'Evapotranspiration'), 'packages.bib')

```

## The model

Decision-makers often wish to have a quantitative basis for their decisions. However,‘hard data’ is often missing or unattainable for many important variables, which can paralyze the decision-making processes or lead decision-makers to conclude that large research efforts are needed before a decision can be made. That is, many variables decision makers must consider cannot be precisely quantified, at least not without unreasonable effort. The major objective of (prescriptive) decision analysis is to support decision-making processes where decision makers are faced with this problem. Following the principles of Decision Analysis can allow us to make forecasts of decision outcomes without precise numbers, as long as probability distributions describing the possible values for all variables can be estimated. 

The `decisionSupport` package implements this as a Monte Carlo simulation, which generates a large number of plausible system outcomes, based on random numbers for each input variable that are drawn from user-specified probability distributions. This approach is useful for determining whether a clearly preferable course of action can be delineated based on the present state of knowledge without the need for further information. If the distribution of predicted system outcomes does not imply a clearly preferable decision option, variables identified as carrying decision-relevant uncertainty can then be targeted by decision-supporting research.

The `mcSimulation` function from the `decisionSupport` package can be applied to conduct decision analysis [@R-decisionSupport]. The function requires three inputs:

1. an `estimate` of the joint probability distribution of the input variables. These specify the names and probability distributions for all variables used in the decision model. These distributions aim to represent the full range of possible values for each component of the model. 
1. a `model_function` that predicts decision outcomes based on the variables named in a separate data table. This R function is customized by the user to address a particular decision problem to provide the decision analysis model.  
1. `numberOfModelRuns`	indicating the number of times to run the model function.

These inputs are provided as arguments to the `mcSimulation` function, which conducts a Monte Carlo analysis with repeated model runs based on probability distributions for all uncertain variables. The data table and model are customized to fit the particulars of a specific decision.

### The `estimate`

To support the model building process we design an input table to store the `estimate` values. The table is stored locally as `limpopo_input_table.csv` and contains many of the basic values for the analysis. This table contains all the input variables used in the model. Their distributions are described by 90% confidence intervals, which are specified by lower (5% quantile) and upper (95% quantile) bounds, as well as the shape of the distribution. This model uses four different distributions:

1.	`const` – a constant value
1.	`norm` – a normal distribution
1.	`tnorm_0_1` – a truncated normal distribution that can only have values between 0 and 1 (useful for probabilities; note that 0 and 1, as well as numbers outside this interval are not permitted as inputs)
1.	`posnorm` – a normal distribution truncated at 0 (only positive values allowed)

For a full list of possible distributions, type `?random.estimate1d ` in your R console. When specifying confidence intervals for truncated distributions, note that approximately 5% of the random values should ‘fit’ within the truncation interval on either side. If there is not enough space, the function will generate a warning (usually it will still work, but the inputs may not look like you intended them to).

### The `model_function`

![Model of the social effects of altered river flows on the sustainability of livelihoods in the Limpopo Basin ](figures/Collective_Model.png)

The decision model is coded as an R function which takes in the variables provided in the data table and generates a model output, such as the Net Present Value. 

In the following we use of various decisionSupport functions, which use the `tidyverse` libraries [@tidyverse2019] including `ggplot2` [@R-ggplot2], `plyr` [@R-plyr] and `dplyr` [@R-dplyr] among others in the [R programming language](https://www.r-project.org/) [@R-base]. 

Here we generate a model as a function using `decisionSupport` library we use the `decisionSupport` functions `vv()` to produce time series with variation from a pre-defined mean and coefficient of variation, `chance_event()` to simulate whether events occur and `discount()` to discount values along a time series and generate a Net Present Value for our intervention comparison.

### Scenarios

The following function defines 3 scenarios:

* Scenario 1 - no eflows: This is a scenario without eflows. Farmers extract water according to their irrigation needs. Extractions are only limited by the minimum water level that allows operating the pumps.
* Scenario 2 - restricted extraction: This is an eflow scenario, in which eflows are interpreted in a purely ecological sense. Whenever eflows aren't achieved, water extraction is curtailed. There are no measures to add water to the river in such events.
* Scenario 3 - dam releases: This is an eflow scenario, in which eflows are interpreted as encompassing the ecological as well as the smallholder irrigation requirement. In case eflows aren't naturally met, water is released from upstream dams to ensure eflows. Extraction by smallholder farmers is restricted only by the ability to operate the pumps.

```{r make_variables, include=FALSE}
input_table<-"data/limpopo_input_table.csv"

make_variables <- function(est,n=1){ x <- random(rho=est, n=n)
for(i in colnames(x)) assign(i, as.numeric(x[1,i]),envir=.GlobalEnv)}

# run the function on the input_table
make_variables(estimate_read_csv(input_table))
```


```{r model}
limpopo_decision_function <- function(x, varnames){


# generating boundary conditions for the simulation run 

# how much rainwater is available
# for now we used data from some random climate diagram on the internet
rainfall<-sapply(1:12,function(x) eval(parse(text=paste0("prec_",x))))

effective_rainfall<-sapply(rainfall,function(x) min(x,effprec_high))
effective_rainfall<-sapply(effective_rainfall,function(x) max(x,effprec_low))


# We compute crop water needs based on ET0 (computed based on the Hargreaves
# Samani equation, as implemented in the Evapotranspiration package). Input
# temperature data comes from the NASAPOWER dataset (accessed through the 
# nasapower package)
# The data will be based on scenarios that represent conditions during real
# years in the past
# To get from ET0 to crop water use, we need to multiply ET0 with a crop
# coefficient (kc), which is estimated for each month

ET0<-sapply(1:12,function(x) eval(parse(text=paste0("ET0_",x)))) # in mm

kc<-sapply(1:12,function(x) eval(parse(text=paste0("kc_",x)))) # in mm

cropwat_need<-ET0*kc # in mm

irrigation_need<-cropwat_need-effective_rainfall # in mm


# define river flow and eflow for each month ####
# Base river flow data from 1920 to 2010, Letaba River at EWR site EWR4 (Letaba Ranch upstream Little Letaba confluence)
pre_livestock_river_flow<-sapply(1:12,function(x) eval(parse(text=paste0("river_flow_",x)))) # in m3 / month
eflow<-sapply(1:12,function(x) eval(parse(text=paste0("eflow_",x)))) # in m3 / month

# watering livestock
# assuming that this is more or less stable throughout the year, but varies a bit
livestock_water_needs<-vv(livestock_water_need,var_CV,12)

# assuming that the eflows aren't affecting ability to water livestock and that there's always enough
# water for all the livestock
river_flow<-pre_livestock_river_flow-livestock_water_needs

# calculating the farmed area

demand_for_farm_area<-n_subsistence_farmers*necessary_farm_size_per_household

farmed_area<-min(available_area, demand_for_farm_area)*(1-unused_sociopolit)

total_cropwater_need<-cropwat_need*farmed_area*10 # total water need in m3 (the 10 is the mm to m3/ha conversion)
total_effective_rainfall<-effective_rainfall*farmed_area*10 # total effective rainfall

# total irrigation need
total_irrigation_need<-total_cropwater_need-total_effective_rainfall # in m3

# water losses are calculated from the efficiency of the pumps and the water allocation
efficiency_pumps<-vv(effi_pump,var_CV,12)
efficiency_irrig_scheduling<-vv(effi_sched,var_CV,12)
efficiency_pumps<-sapply(efficiency_pumps, function(x)  min(x,1))
efficiency_pumps<-sapply(efficiency_pumps, function(x)  max(x,0))
efficiency_irrig_scheduling<-sapply(efficiency_irrig_scheduling, function(x)  min(x,1))
efficiency_irrig_scheduling<-sapply(efficiency_irrig_scheduling, function(x)  max(x,0))

water_losses_share<-(1-efficiency_pumps*efficiency_irrig_scheduling)

irrigation_water_need<-total_irrigation_need/(1-water_losses_share)

# eflow scenario 1 - no eflows

scen1_usable_river_flow<-sapply(1:12,function(x) max(0,river_flow[x]-minimum_flow_to_operate_pumps))

# eflow scenario 2 - eflows as a limit to extraction only

# eflows are to be ensured whenever there is more water in the river than the eflow
# requirement would mandate, i.e. farmers aren't allowed to extract water beyond
# the eflow requirement.
# no measures are taken to ensure that eflows are maintained at times when
# the present flow is below the eflow requirement. 

scen2_usable_river_flow<-sapply(1:12,function(x) max(0,river_flow[x]-max(eflow[x],minimum_flow_to_operate_pumps)))

# eflow scenario 3 - eflows are assured by dam releases

# whenever the present flow is below the eflow requirement, water is released
# from an upstream dam to ensure that the eflows are met.

adj_river_flow <- sapply(1:12, function(x)
  max(river_flow[x], eflow[x]))

required_dam_release <- adj_river_flow - river_flow

scen3_usable_river_flow <-
  sapply(1:12, function(x)
    max(0, adj_river_flow[x] - minimum_flow_to_operate_pumps))

# calculate how much water gets extracted from the river

scen1_extracted_river_water <-
  sapply(1:12, function(x)
    min(scen1_usable_river_flow[x], irrigation_water_need[x]))
scen2_extracted_river_water <-
  sapply(1:12, function(x)
    min(scen2_usable_river_flow[x], irrigation_water_need[x]))
scen3_extracted_river_water <-
  sapply(1:12, function(x)
    min(scen3_usable_river_flow[x], irrigation_water_need[x]))

# calculate damage to crop production due to lack of irrigation water
scen1_water_shortfall <-
  sapply(1:12, function (x)
    max(0, irrigation_water_need[x] - scen1_extracted_river_water[x]))
scen2_water_shortfall <-
  sapply(1:12, function (x)
    max(0, irrigation_water_need[x] - scen2_extracted_river_water[x])) 
scen3_water_shortfall <-
  sapply(1:12, function (x)
    max(0, irrigation_water_need[x] - scen3_extracted_river_water[x]))

scen1_irrigation_shortfall<-scen1_water_shortfall*(1-water_losses_share)
scen2_irrigation_shortfall<-scen2_water_shortfall*(1-water_losses_share)
scen3_irrigation_shortfall<-scen3_water_shortfall*(1-water_losses_share)

scen1_crop_water_gap<-scen1_irrigation_shortfall/(cropwat_need*farmed_area*10)
scen2_crop_water_gap<-scen2_irrigation_shortfall/(cropwat_need*farmed_area*10)
scen3_crop_water_gap<-scen3_irrigation_shortfall/(cropwat_need*farmed_area*10)

# calculate how much water is left after farmers extracted water
scen1_river_flow_downstream<-river_flow-scen1_extracted_river_water
scen2_river_flow_downstream<-river_flow-scen2_extracted_river_water
scen3_river_flow_downstream<-adj_river_flow-scen3_extracted_river_water

# calculate outputs and differences 

return(list(scen1_downstream_river_flow=scen1_river_flow_downstream,
            scen2_downstream_river_flow=scen2_river_flow_downstream,
            scen3_downstream_river_flow=scen3_river_flow_downstream,
            scen3_dam_release=required_dam_release,
            Downstream_difference_2_vs_1=scen2_river_flow_downstream-scen1_river_flow_downstream,
            Downstream_difference_3_vs_1=scen3_river_flow_downstream-scen1_river_flow_downstream,
            scen1_crop_water_gap=scen1_crop_water_gap,
            scen2_crop_water_gap=scen2_crop_water_gap,
            scen3_crop_water_gap=scen3_crop_water_gap,
            Crop_water_gap_difference_2_vs_1=scen2_crop_water_gap-scen1_crop_water_gap,
            Crop_water_gap_difference_3_vs_1=scen3_crop_water_gap-scen1_crop_water_gap,
            Mean_Crop_water_gap_difference_2_vs_1=mean(scen2_crop_water_gap-scen1_crop_water_gap),
            Mean_Crop_water_gap_difference_3_vs_1=mean(scen3_crop_water_gap-scen1_crop_water_gap)))
  
}

```

#### Perform a Monte Carlo simulation with scenarios 

Using the model function above, we can perform a Monte Carlo simulation with the `mcSimulation()` function from `decisionSupport`. This function generates distributions of all variables in the input table as well as the specified model outputs (see `return()` function above) by calculating random draws in our defined `limpopo_decision_function()`. We run a  visual assessment to ensure that all the variables in the input table are included in the model (erroneous variables listed there can cause issues with some of the post-hoc analyses). 

The `numberOfModelRuns` argument is an integer indicating the number of model runs for the Monte Carlo simulation. Unless the model function is very complex, 10,000 runs is a reasonable choice (for complex models, 10,000 model runs can take a while, so especially when the model is still under development, it often makes sense to use a lower number).

We first make a scenario file, for which we can use data for 1980 to 2020.

```{r}
# load data from Evapotranspiration
data("constants")

# use nasapower for evapotranspiration data
ag_d <- get_power(
  community = "ag",
  lonlat = c(31.08,-23.7),
  pars = c("T2M_MAX", "T2M_MIN", "PRECTOTCORR"),
  dates = c("1981-01-01", "2020-12-31"),
  temporal_api = "daily"
)

# choose years of assessment
years<-1981:2009

# name variables
colnames(ag_d)[c(3:5, 8, 9, 10)] <-
  c("Year", "Month", "Day", "Tmax", "Tmin", "Precipitation")

Inputs <- ReadInputs(c("Tmin", "Tmax"), ag_d, stopmissing = c(50, 50, 50))

# apply ET.HargreavesSamani from the Evapotranspiration library
ET <-
  ET.HargreavesSamani(
    Inputs,
    constants,
    ts = "daily",
    message = "yes",
    AdditionalStats = "yes",
    save.csv = "no"
  )

ETdata <- data.frame(year = years)
ETdata[, month.abb[1:12]] <- NA
for (yyyy in years)
  ETdata[which(ETdata$year == yyyy), 2:13] <-
  ET$ET.Monthly[as.character(yyyy + 0:11 / 12)]

rain <-
  aggregate(ag_d$Precipitation,
            by = list(ag_d$Year, ag_d$Month),
            FUN = sum)
raindata <- data.frame(year = years)
raindata[, month.abb[1:12]] <- NA
for (yyyy in years)
  raindata[which(raindata[, 1] == yyyy), 2:13] <-
  rain[which(rain[, 1] == yyyy), 3]


scenario_variables <-
  c(paste0("river_flow_", 1:12),
    paste0("ET0_", 1:12),
    paste0("prec_", 1:12),
    paste0("eflow_", 1:12))

Scenarios <- data.frame(Variable = scenario_variables, param = "both")

eflows<-read.csv("data/Letaba_eflows_exceedence_m3_per_s.csv",fileEncoding="UTF-8-BOM")
eflowsort <-
  eflows[, c(1, order(unlist(sapply(colnames(eflows)[2:13], function(x)
    which(month.abb[1:12] == x)))) + 1)]
eflow_exceedance<-eflowsort[which(eflowsort$Exceedence == 80),]
eflow_per_month<-eflow_exceedance[2:13]*c(31,28,31,30,31,30,31,31,30,31,30,31)*3600*24

# read data of present data 
present_flows<-read.csv("data/Letaba_modelled_present_flows_m3_per_s.csv",fileEncoding="UTF-8-BOM")
presentflowsort <-
  present_flows[, c(1, order(unlist(sapply(colnames(present_flows)[2:13], function(x)
    which(month.abb[1:12] == x)))) + 1)]
presentflow_permonth<-data.frame(cbind(presentflowsort[,1],t(t(presentflowsort[,2:13])*c(31,28,31,30,31,30,31,31,30,31,30,31)*3600*24)))
colnames(presentflow_permonth)[1]<-"Year"

# The hydrological year in the input file starts in October and runs until September. We're assuming here that the year given for each year corresponds to the first calendar year of this period.

presentflow_permonth[2:nrow(presentflow_permonth),month.abb[1:9]]<-
  presentflow_permonth[1:(nrow(presentflow_permonth)-1),month.abb[1:9]]

presentflow_permonth[1,month.abb[1:9]]<-NA

for (yyyy in years)
{
  Scenarios[, paste0("y_", yyyy)] <- NA
  for (mm in 1:12)
  {
    Scenarios[which(Scenarios$Variable == paste0("ET0_", mm)), paste0("y_", yyyy)] <-
      ETdata[which(ETdata$year == yyyy), 1 + mm]
    Scenarios[which(Scenarios$Variable == paste0("prec_", mm)), paste0("y_", yyyy)] <-
      raindata[which(raindata$year == yyyy), 1 + mm]
    Scenarios[which(Scenarios$Variable == paste0("river_flow_", mm)), paste0("y_", yyyy)] <-
      presentflow_permonth[which(presentflow_permonth$Year == yyyy), 1 + mm]
    Scenarios[which(Scenarios$Variable == paste0("eflow_", mm)), paste0("y_", yyyy)] <-
      eflow_per_month[mm]
  }
}

# natural flows (this is for information and not used in the model)
natural_flows<-read.csv("data/Letaba_modelled_natural_flows_m3_per_s.csv",fileEncoding="UTF-8-BOM")

# write the scenarios file
write.csv(Scenarios, "data/scenarios_1980_2020.csv", row.names = FALSE)
```
Here we run the model with the `scenario_mc` function from the `decisionSupport` package [@R-decisionSupport]. The function essentially generates a Monte Carlo model with data from existing scenarios for some of the model inputs.

```{r mcSimulation_scenarios}
# run the model with the scenario_mc function 
mcSimulation_results <-
  scenario_mc(
    base_estimate = decisionSupport::estimate_read_csv("data/limpopo_input_table.csv"),
    scenarios = read.csv("data/scenarios_1980_2020.csv", fileEncoding =
                           "UTF-8-BOM"),
    model_function = limpopo_decision_function,
    numberOfModelRuns = 2e2, #run 1,000 times
    functionSyntax = "plainNames"
  )
```

## Results

The results will refer to the scenarios we formulated in the model:

* Scenario 1, no eflows: This is a scenario without eflows. Farmers extract water according to their irrigation needs. Extractions are only limited by the minimum water level that allows operating the pumps. The results of the simulations of this scenario forms a baseline for comparisons. We use this to describe the results of other simulations and for testing the model simulations of the other scenarios. We do this by subtracting the farm level water gap resulting from this scenario from the water gap for each of the other scenarios.

* Scenario 3, dam releases: This is an eflow scenario, in which eflows are interpreted as encompassing the ecological as well as the smallholder irrigation requirement. In case eflows aren't naturally met, water is released from upstream dams to ensure eflows. Extraction by smallholder farmers is restricted only by the ability to operate the pumps.

#### Plot Net Present Value (NPV) distributions 

We can use the `plot_distributions()` function to produce one of the several plotting options for distribution outputs. This shows us an overlay of the full results of the Monte Carlo model of the decision options, i.e. the expected NPV if we choose to do the intervention `Interv_NPV` or not do the intervention `NO_Interv_NPV`.

Here we plot the difference in farm level crop water gap (i.e. how much water is missing from the smallholder farmers needs) between the baseline Scenario 1, no eflows and eflow Scenario 2, restricted extraction. In this eflow scenario eflows are interpreted in a purely ecological sense. Whenever eflows aren't achieved, water extraction is curtailed. There are no measures to add water to the river in such events.

```{r}
decisionSupport::plot_distributions(mcSimulation_object = mcSimulation_results,
                                    vars = c("Mean_Crop_water_gap_difference_2_vs_1"),
                                    method = 'smooth_simple_overlay',
                                    base_size = 7)
```

In short, an eflow scenario that simply curtails extraction but doesn't alleviate sub-eflow flows, is likely to cause considerable irrigation water shortages.

Here's the difference between the crop water gap in eflow scenario 3 (incl. dam releases) vs. the baseline (no eflows):

```{r}
decisionSupport::plot_distributions(mcSimulation_object = mcSimulation_results,
                                    vars = c("Mean_Crop_water_gap_difference_3_vs_1"),
                                    method = 'smooth_simple_overlay',
                                    base_size = 7)

```

An eflow scenario that includes dam releases to ensure eflows (scenario 3) benefits farmers by effectively precluding irrigation water shortfalls.

#### Flow analysis

Here we plot the distribution of downstream flow difference over the entire simulated year. For this we use the `plot_cashflow()` function, which uses the `Downstream_difference` output from the `mcSimulation()` function to show the difference in downstream river flow over time.

First for scenario 2 vs. the no-eflow baseline:

```{r plot_cashflow_downstream_2}
plot_cashflow(mcSimulation_object = mcSimulation_results, 
              cashflow_var_name = "Downstream_difference_2_vs_1",
              y_axis_name = "Downstream difference (m3)",
              x_axis_name = "Month")
```

Now for scenario 3 vs. the no-eflow baseline:

```{r plot_cashflow_downstream_3}
plot_cashflow(mcSimulation_object = mcSimulation_results, 
              cashflow_var_name = "Downstream_difference_3_vs_1",
              y_axis_name = "Downstream difference (m3)",
              x_axis_name = "Month")
```

And these are the dam releases required to maintain scenario 3:

```{r plot_cashflow_downstream_dam_releases}
plot_cashflow(mcSimulation_object = mcSimulation_results, 
              cashflow_var_name = "scen3_dam_release",
              y_axis_name = "Water release from upstream dams (m3)",
              x_axis_name = "Month")
```

Here a similar plot of `Crop_water_gap_difference` to show the crop water gap over time.

```{r plot_cashflow_downstream_cropwater_gap}
plot_cashflow(mcSimulation_object = mcSimulation_results, 
              cashflow_var_name = "Crop_water_gap_difference_2_vs_1",
              y_axis_name = "Crop water gap difference (share crop need)",
              x_axis_name = "Month")
```

```{r plot_cashflow_downstream_cropwater_gap_2}
plot_cashflow(mcSimulation_object = mcSimulation_results, 
              cashflow_var_name = "Crop_water_gap_difference_3_vs_1",
              y_axis_name = "Crop water gap difference (share crop need)",
              x_axis_name = "Month")
```

#### Projection to Latent Structures (PLS) analysis

Projection to Latent Structures (PLS), also sometimes known as Partial Least Squares regression is a multivariate statistical technique that can deal with multiple colinear dependent and independent variables [@wold_pls-regression_2001]. It can be used as another means to assess the outcomes of a Monte Carlo model. Read more in ['A Simple Explanation of Partial Least Squares' by Kee Siong Ng](http://users.cecs.anu.edu.au/~kee/pls.pdf).

Variable Importance in Projection (VIP) scores estimate the importance of each variable in the projection used in a PLS mode. VIP is a parameter used for calculating the cumulative measure of the influence of individual $X$-variables on the model. For a given PLS dimension, $a$, the squared PLS weight $(Wa)2$ of that term is multiplied by the explained sum of squares ($SS$) of that $PLS$ dimension; and the value obtained is then divided by the total explained $SS$ by the PLS model and multiplied by the number of terms in the model. The final $VIP$ is the square root of that number.

$VIP_{PLS} = K\times (\frac{[\sum_{a=1}^{A}(W_{a}^{2} \times SSY_{comp,a})]}{SSY_{cum}})$

The VIP is a weighted combination overall components of the squared PLS weights ($Wa$), where $SSY_{comp,a}$ is the sum of squares of $Y$ explained by component $a$, $A$ is the total number of components, and $K$ is the total number of variables. The average VIP is equal to 1 because the $SS$ of all VIP values is equal to the number of variables in $X$. A variable with a VIP Score close to or greater than 1 (one) can be considered important. The input is a PLS model and the output is a set of column vectors equal in length to the number of variables included in the model. See @galindo-prieto_variable_2014 for a detailed description of variations of VIP analysis.

We apply a post-hoc analysis to the `mcSimulation()` outputs with `plsr.mcSimulation()` to determine the *Variable Importance in the Projection (VIP)* score and coefficients of a *Projection to Latent Structures (PLS)* regression model. This function uses the outputs of the `mcSimulation()` selecting all the input variables from the decision analysis function in the parameter `object` and then runs a PLS regression with an outcome variable defined in the parameter `resultName`. We use the code `names(mcSimulation_results$y)[73]` to select the outcome variable `r names(mcSimulation_results$y)[73]`, which is an element of the list `y` in our `mcSimulation_results` outputs (this must be a character element). 

```{r}
mcSimulation_pls<-mcSimulation_results
mcSimulation_pls$x<-mcSimulation_pls$x[, !names(mcSimulation_pls$x) == "Scenario"]

pls_result <- plsr.mcSimulation(object = mcSimulation_pls,
                  resultName = "Mean_Crop_water_gap_difference_2_vs_1", ncomp = 1)

```

We run the `plot_pls()` on the results from `plsr.mcSimulation()` with a number of standard settings. The length of the bars is equal to VIP with a vertical line at '1' on the x-axis indicating a standard cut-off for VIP used for variable selection. The overall plot only shows those variables with a VIP > 0.8, which is the common threshold for variable selection [@lanzanova_improving_2019, @luedeling_decision-focused_2016]. The colors of the bars represent the positive or negative coefficient of the given input variable with the output variable.

Here we import the input table again to replace the labels for the variables on the y-axis. The input table can include a `label` and `variable` column. The standard labels (from the `variable` column) are usually computer readable and not very nice for a plot. The `plot_pls()` function uses the text in the `label` column as replacement for the default text in the `variable` column.  

Here's the plot for a PLS analysis for the outcome variable Mean_Crop_water_gap_difference_2_vs_1:

```{r}
input_table <- read.csv("data/limpopo_input_table.csv")

plot_pls(pls_result, input_table = input_table, threshold = 0.5)

```

Here's the plot for a PLS analysis for the outcome variable Mean_Crop_water_gap_difference_3_vs_1:

```{r}
input_table <- read.csv("data/limpopo_input_table.csv")

pls_result <- plsr.mcSimulation(object = mcSimulation_pls,
                  resultName = "Mean_Crop_water_gap_difference_3_vs_1", ncomp = 1)

plot_pls(pls_result, input_table = input_table, threshold = 0.5)

```

### Addendum

The objective of the procedures used in the `decisionSupport` package is to make it easier for analysts to produce decision-relevant information that adequately reflects the imperfect nature of the information we usually have. Adding  probabilistic elements to a simulation adds substantial value to an analysis. Mostly, it avoids making spurious assumptions, replacing uncertainty with ‘best bets’ and producing results that do not reflect the knowledge limitations that make decision-making so challenging. More information on all this is contained in the [decisionSupport manual](https://cran.r-project.org/web/packages/decisionSupport/decisionSupport.pdf), especially under `welfareDecisionAnalysis`.

### References

